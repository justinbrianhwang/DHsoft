# Main evaluation system
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ì˜ë£Œ CRF ë¬¸í•­ ê¸°ë°˜ OCR ì •í™•ë„ í‰ê°€ (ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜)
- PDF í…ìŠ¤íŠ¸/ì´ë¯¸ì§€ ì¶”ì¶œ â†’ ë¬¸í•­ ì¶”ì¶œ â†’ ë¬¸í•­ ë§¤ì¹­ â†’ í†µê³„/ë¦¬í¬íŒ… ì €ì¥
- ë ˆì´ì•„ì›ƒ ì¸ì§€(ì¢Œí‘œ í™œìš©) / ì˜ˆì‚° ê°€ë“œë ˆì¼ / ì•ˆì „ì¥ì¹˜(.env) ì§€ì›
"""

import os
import time
from pathlib import Path
from datetime import datetime
import pandas as pd
from src.utils.accuracy_calculator import cer, wer, accuracy, gpt_semantic_confidence
from src.utils.pdf_processor import iter_pdf_pages_text, iter_pdf_pages_as_images
from src.ocr.naver_clova_client import NaverOCRClient
from src.extractors.medical_crf_extractor import MedicalCRFQuestionExtractor
from src.matchers.enhanced_matcher import EnhancedQuestionMatcher
from src.utils.budget_manager import BudgetManager  # <- ì´ í´ë˜ìŠ¤ë¥¼ ì“°ê³  ìˆë‹¤ë©´ í•„ìš”
from src.utils.accuracy_calculator import (
    cer, wer, accuracy,
    calc_overall_statistics,
    summarize_by_category, summarize_by_page, summarize_by_type,
    serialize_matches,
)

# ì™¸ë¶€ ëª¨ë“ˆ
try:
    from dotenv import load_dotenv
    load_dotenv()
    print(" .env íŒŒì¼ ë¡œë“œ ì™„ë£Œ")
except Exception:
    print("  python-dotenv ì—†ìŒ - ì‹œìŠ¤í…œ í™˜ê²½ë³€ìˆ˜ ì‚¬ìš©")

# ë‚´ë¶€ ëª¨ë“ˆ
from src.extractors.medical_crf_extractor import MedicalCRFQuestionExtractor
from src.matchers.enhanced_matcher import EnhancedQuestionMatcher
from src.ocr.naver_clova_client import NaverOCRClient
from src.utils.pdf_processor import (
    iter_pdf_pages_text,
    iter_pdf_pages_as_images,
    # ì„ íƒ: ë ˆì´ì•„ì›ƒì´ í•„ìš”í•  ë•Œë§Œ ì‚¬ìš© (ì—†ìœ¼ë©´ í´ë°±)
    # iter_pdf_layout  # ì¶”ì¶œê¸° ë‚´ë¶€ì—ì„œ ì‚¬ìš© ê¶Œì¥
)

from src.utils.accuracy_calculator import (
    calc_overall_statistics,
    summarize_by_category,
    summarize_by_page,
    summarize_by_type,
    serialize_matches,
    cer, wer, accuracy,                 # â† ì¶”ê°€
    gpt_semantic_confidence,            # â† ì„ íƒ: ì˜ë¯¸ ìœ ì‚¬ ì‹ ë¢°ë„ ì“°ë©´ ìœ ì§€
)
from src.utils.text_normalizer import safe_mkdir

# ì„ íƒ: ì˜ˆì‚° ë§¤ë‹ˆì €ê°€ ìˆìœ¼ë©´ ì‚¬ìš©(ì—†ìœ¼ë©´ ë¬´ì‹œ)
_BM = None
try:
    from src.utils.budget_manager import BudgetManager  # optional
    _BM = BudgetManager()
except Exception:
    _BM = None

# ------------------------------------------
# í™˜ê²½ì„¤ì • í”Œë˜ê·¸/í•œë„
# ------------------------------------------
def _env_bool(key: str, default: bool) -> bool:
    v = os.getenv(key, str(default)).strip().lower()
    return v in ("1", "true", "yes", "y")

def _env_int(key: str, default: int) -> int:
    try:
        return int(os.getenv(key, default))
    except Exception:
        return default

ENABLE_LAYOUT_AWARE = _env_bool("ENABLE_LAYOUT_AWARE", True)
MAX_PAGES_PER_RUN = _env_int("MAX_PAGES_PER_RUN", 10_000)          # ì‚¬ì‹¤ìƒ ë¬´ì œí•œ(ì•ˆì „ì¥ì¹˜)
MAX_QUESTIONS_PER_RUN = _env_int("MAX_QUESTIONS_PER_RUN", 1_000_000)

RESULTS_DIR = Path("crf_evaluation_results")
RESULTS_DIR.mkdir(exist_ok=True)

class MedicalCRFOCREvaluator:
    """ì˜ë£Œ CRF ë¬¸í•­ ê¸°ë°˜ OCR í‰ê°€ ì‹œìŠ¤í…œ (ì¡°ë¦½/ì‹¤í–‰ ë‹´ë‹¹)"""

    def __init__(self, api_key: str = None):
        self.api_key = api_key or os.getenv("OPENAI_API_KEY")

        # ì°¸ì¡° PDF ì¶”ì¶œê¸° (ì›ë³¸ìš©)
        self.ref_extractor = MedicalCRFQuestionExtractor(api_key=self.api_key)

        # ë‚˜ë¨¸ì§€ ì´ˆê¸°í™” ì½”ë“œ...
        self.matcher = EnhancedQuestionMatcher()
        self.budget_manager = BudgetManager()
        
        self.results_dir = Path("crf_evaluation_results")
        self.results_dir.mkdir(exist_ok=True)

        # â˜… OCR í´ë¼ì´ì–¸íŠ¸ (í´ë°±/ìŠ¤ìº” ì²˜ë¦¬ì—ì„œ ì‚¬ìš©)
        self.ocr_client = NaverOCRClient()
        self.extractor = self.ref_extractor

    def evaluate(self, reference_pdf: str, scanned_pdf: str):
        print("\n" + "=" * 80)
        print(" ì˜ë£Œ CRF ë¬¸í•­ ê¸°ë°˜ OCR ì •í™•ë„ í‰ê°€")
        print("=" * 80)

        try:
            # 1) ë ˆì´ì•„ì›ƒ ê¸°ë°˜ ì¶”ì¶œ (í‘œ/í–‰ì— ê°•í•¨)
            print("\n 1ë‹¨ê³„: ì°¸ì¡° PDFì—ì„œ ë¬¸í•­ ì¶”ì¶œ")
            ref_questions = self.ref_extractor.extract_questions_with_layout(reference_pdf)
        except Exception as e:
            print("  ë ˆì´ì•„ì›ƒ ì¸ì§€ ì¶”ì¶œ ì‹¤íŒ¨ â†’ í…ìŠ¤íŠ¸/OCR í´ë°±:", e)
            ref_questions = []
            for page_num, text in self._get_reference_pages_with_fallback(reference_pdf):
                print(f"  {page_num}í˜ì´ì§€ ë¬¸í•­ ì¶”ì¶œ ì¤‘...")
                ref_qs = self.ref_extractor.extract_questions(text, page_num=page_num)
                print(f"    {len(ref_qs)}ê°œ ë¬¸í•­ ë°œê²¬")
                ref_questions.extend(ref_qs)
        
        # 2) ìŠ¤ìº” PDF OCR â†’ ë¬¸í•­ ì¶”ì¶œ
        print("\n 2ë‹¨ê³„: ìŠ¤ìº” PDF OCR ë° ë¬¸í•­ ì¶”ì¶œ")
        ocr_questions = self._extract_ocr_questions(scanned_pdf)

        # 3) ë¬¸í•­ ë§¤ì¹­
        print("\n 3ë‹¨ê³„: ë¬¸í•­ ë§¤ì¹­ ë° ë¹„êµ")
        all_matches = self._match_by_page(ref_questions, ocr_questions)
        
        self._inject_text_metrics(all_matches)  # â˜… ì´ ì¤„ ì¶”ê°€

        # ì•ˆì „ì¥ì¹˜: ë¬¸í•­ ìƒí•œ
        if len(all_matches) > MAX_QUESTIONS_PER_RUN:
            all_matches = all_matches[:MAX_QUESTIONS_PER_RUN]

        # 4) í†µê³„
        print("\n4ë‹¨ê³„: í†µê³„ ê³„ì‚°")
        overall = calc_overall_statistics(all_matches)
        by_category = summarize_by_category(all_matches)
        by_page = summarize_by_page(all_matches)
        by_type = summarize_by_type(all_matches)

        stats = {
            **overall,
            "category_statistics": by_category,
            "page_statistics": by_page,
            "type_statistics": by_type,
        }

        # 5) ì¶œë ¥/ì €ì¥
        self._print_results(stats, all_matches)
        self._save_results(stats, all_matches, ref_questions, ocr_questions)

        # ì„ íƒ: ì˜ˆì‚° ì”ì—¬ ì¶œë ¥
        if _BM:
            try:
                print(f"\n ì˜ˆì‚° ì”ì—¬(ì¼): ${_BM.remaining_today():.4f} / (ì›”): ${_BM.remaining_month():.4f}")
            except Exception:
                pass

        return {
            "statistics": stats,
            "matches": all_matches,
            "reference_questions": ref_questions,
            "ocr_questions": ocr_questions,
        }

    # ---------------------------
    # (1) ì°¸ì¡° PDF ì¶”ì¶œ
    # ---------------------------
    def _extract_reference_questions(self, reference_pdf: str):
        ref_questions = []
        page_count = 0

        # ë ˆì´ì•„ì›ƒ ì¸ì§€ ëª¨ë“œê°€ ê°€ëŠ¥í•˜ë©´ ì¶”ì¶œê¸° ë©”ì„œë“œ ì‚¬ìš©
        if ENABLE_LAYOUT_AWARE and hasattr(self.extractor, "extract_questions_with_layout"):
            try:
                # ì „ì²´ ë¬¸ì„œë¥¼ í•œ ë²ˆì— ë ˆì´ì•„ì›ƒ ì¸ì§€ ì¶”ì¶œ (extractor ë‚´ë¶€ì—ì„œ í˜ì´ì§€/ì¹´í…Œê³ ë¦¬ íƒœê¹…)
                qlist = self.extractor.extract_questions_with_layout(reference_pdf) or []
                for q in qlist:
                    q["source"] = "reference"
                ref_questions.extend(qlist)

                # í˜ì´ì§€ë³„ ë¡œê·¸(ê°„ëµí™”: ì§ì ‘ ì§‘ê³„)
                page_groups = {}
                for q in qlist:
                    p = q.get("page_number", -1)
                    page_groups.setdefault(p, []).append(q)
                # ìƒí•œ ì ìš©
                for p in sorted(page_groups):
                    page_count += 1
                    if page_count > MAX_PAGES_PER_RUN:
                        break
                    page_questions = page_groups[p]
                    cat_count = {}
                    for q in page_questions:
                        cat = q.get("question_category", "unknown")
                        cat_count[cat] = cat_count.get(cat, 0) + 1
                    print(f"   {p}í˜ì´ì§€ ë¬¸í•­ ì¶”ì¶œ ì¤‘...")
                    print(f"     {len(page_questions)}ê°œ ë¬¸í•­ ë°œê²¬")
                    for cat, c in cat_count.items():
                        if cat and cat != "unknown":
                            print(f"       - {cat}: {c}ê°œ")
                return ref_questions
            except Exception as e:
                print(f"  ë ˆì´ì•„ì›ƒ ì¸ì§€ ì¶”ì¶œ ì‹¤íŒ¨ â†’ í…ìŠ¤íŠ¸ ê¸°ë°˜ìœ¼ë¡œ í´ë°±: {e}")

        # í´ë°±: í…ìŠ¤íŠ¸ ê¸°ë°˜ í˜ì´ì§€ ë°˜ë³µ
        for page_num, text in self._get_reference_pages_with_fallback(reference_pdf):
            page_count += 1
            if page_count > MAX_PAGES_PER_RUN:
                break
            print(f"   {page_num}í˜ì´ì§€ ë¬¸í•­ ì¶”ì¶œ ì¤‘...")
            page_questions = self.extractor.extract_questions(text, page_num)
            for q in page_questions:
                q["source"] = "reference"
            ref_questions.extend(page_questions)

            # ì¹´í…Œê³ ë¦¬ ì§‘ê³„
            cat_count = {}
            for q in page_questions:
                cat = q.get("question_category", "unknown")
                cat_count[cat] = cat_count.get(cat, 0) + 1
            print(f"     {len(page_questions)}ê°œ ë¬¸í•­ ë°œê²¬")
            for cat, c in cat_count.items():
                if cat and cat != "unknown":
                    print(f"       - {cat}: {c}ê°œ")

        return ref_questions

    # ---------------------------
    # (2) ìŠ¤ìº” PDF(OCR) ì¶”ì¶œ
    # ---------------------------
    def _extract_ocr_questions(self, scanned_pdf: str):
        ocr_questions = []
        page_count = 0

        for page_num, image_path in iter_pdf_pages_as_images(scanned_pdf, out_dir=self.results_dir):
            page_count += 1
            if page_count > MAX_PAGES_PER_RUN:
                try:
                    image_path.unlink(missing_ok=True)
                except Exception:
                    pass
                break

            print(f"  {page_num}í˜ì´ì§€ OCR ì²˜ë¦¬ ì¤‘...")
            ocr_result = self.ocr_client.extract_text_from_image(str(image_path))

            if ocr_result.get("success"):
                # ì¢Œí‘œ ë¸”ë¡ì´ ìˆê³ , ì¶”ì¶œê¸°ê°€ ì´ë¥¼ ì²˜ë¦¬í•  ìˆ˜ ìˆìœ¼ë©´ ë ˆì´ì•„ì›ƒ-aware ì¶”ì¶œ
                blocks = ocr_result.get("blocks") or []
                if ENABLE_LAYOUT_AWARE and blocks and hasattr(self.ref_extractor, "extract_from_blocks"):
                    try:
                        page_questions = self.ref_extractor.extract_from_blocks(blocks, page_num=page_num)
                    except Exception:
                        page_questions = self.ref_extractor.extract_questions(ocr_result["text"], page_num)
                else:
                    page_questions = self.ref_extractor.extract_questions(ocr_result["text"], page_num)

                for q in page_questions:
                    q["source"] = "ocr"
                    q["ocr_confidence"] = ocr_result.get("confidence", 0.0)
                ocr_questions.extend(page_questions)

                print(f"   OCR ì‹ ë¢°ë„: {ocr_result.get('confidence', 0.0):.2f}, {len(page_questions)}ê°œ ë¬¸í•­ ì¶”ì¶œ")

            # ì„ì‹œ ì´ë¯¸ì§€ ì œê±°
            try:
                image_path.unlink(missing_ok=True)
            except Exception:
                pass

        return ocr_questions

    # ---------------------------
    # (3) í˜ì´ì§€ ë‹¨ìœ„ ë§¤ì¹­
    # ---------------------------
    def _match_by_page(self, ref_questions, ocr_questions):
        all_matches = []
        ref_pages = sorted(set(q.get("page_number", -1) for q in ref_questions))
        ocr_pages = sorted(set(q.get("page_number", -1) for q in ocr_questions))
        common_pages = [p for p in ref_pages if p in ocr_pages]  # â˜…

        for page_num in common_pages:
            ref_page_q = [q for q in ref_questions if q.get("page_number", -1) == page_num]
            ocr_page_q = [q for q in ocr_questions if q.get("page_number", -1) == page_num]
            print(f" {page_num}í˜ì´ì§€: ì°¸ì¡° {len(ref_page_q)}ê°œ, OCR {len(ocr_page_q)}ê°œ ë¬¸í•­")
            page_matches = self.matcher.match_questions(ref_page_q, ocr_page_q)
            for m in page_matches:
                m["page_number"] = page_num
                all_matches.append(m)
        return all_matches

    # ---------------------------
    # (4) ì¶œë ¥/ì €ì¥
    # ---------------------------
    def _print_results(self, stats, matches):
        print("\n" + "=" * 80)
        print("ğŸ“ˆ ì˜ë£Œ CRF ë¬¸í•­ ê¸°ë°˜ í‰ê°€ ê²°ê³¼")
        print("=" * 80)

        print(f"\nğŸ“Š ì „ì²´ í†µê³„:")
        print(f"  â€¢ ì´ ë¬¸í•­ ìˆ˜: {stats['total_questions']}")
        print(f"  â€¢ ë§¤ì¹­ëœ ë¬¸í•­: {stats['matched_questions']}")
        print(f"  â€¢ ì „ì²´ ë§¤ì¹­ë¥ : {stats['match_rate']:.1f}%")
        print(f"  â€¢ í‰ê·  ìœ ì‚¬ë„(ë¬¸ìì—´): {stats['avg_similarity']:.3f}")
        print(f"  â€¢ í‰ê·  CER: {stats['avg_cer']:.3f}")
        print(f"  â€¢ í‰ê·  WER: {stats['avg_wer']:.3f}")
        print(f"  â€¢ í‰ê·  Accuracy: {stats['avg_accuracy']:.3f}")
        print(f"  â€¢ í‰ê·  GPT ì‹ ë¢°ë„: {stats['avg_gpt_confidence']:.3f}")
        print(f"  â€¢ ìœ ì‚¬ë„ ë²”ìœ„: {stats['min_similarity']:.3f} ~ {stats['max_similarity']:.3f}")
        print(f"  â€¢ OCRì—ë§Œ ìˆëŠ” ë¬¸í•­: {stats['ocr_only_questions']}")

        print(f"\nì¹´í…Œê³ ë¦¬ë³„ í†µê³„:")
        for category, cat_stat in stats["category_statistics"].items():
            if cat_stat["total"] > 0:
                rate = cat_stat["matched"] / cat_stat["total"] * 100
                print(f"\n  [{category or 'ë¯¸ë¶„ë¥˜'}]")
                print(f"    â€¢ ì „ì²´: {cat_stat['matched']}/{cat_stat['total']} ({rate:.1f}%)")
                print(f"    â€¢ í‰ê·  ìœ ì‚¬ë„: {cat_stat.get('avg_similarity', 0.0):.3f}")
                if cat_stat["table_items"] > 0:
                    tr = cat_stat["table_matched"] / cat_stat["table_items"] * 100
                    print(f"    â€¢ í‘œ í•­ëª©: {cat_stat['table_matched']}/{cat_stat['table_items']} ({tr:.1f}%)")

        print(f"\ní˜ì´ì§€ë³„ í†µê³„:")
        for page, page_stat in sorted(stats["page_statistics"].items()):
            if page_stat["total"] > 0:
                rate = page_stat["matched"] / page_stat["total"] * 100
                avg_sim = (
                    sum(page_stat["similarities"]) / len(page_stat["similarities"])
                    if page_stat["similarities"]
                    else 0.0
                )
                print(f"  â€¢ {page}í˜ì´ì§€: {page_stat['matched']}/{page_stat['total']} "
                      f"({rate:.1f}%), í‰ê·  ìœ ì‚¬ë„: {avg_sim:.3f}")

        print(f"\nï¸ ë¬¸í•­ ìœ í˜•ë³„ í†µê³„:")
        type_name_map = {
            "table_row": "í‘œ í•­ëª©",
            "multiple_choice": "ë‹¤ì¤‘ì„ íƒ",
            "single_choice": "ë‹¨ì¼ì„ íƒ",
            "yes_no": "ì˜ˆ/ì•„ë‹ˆì˜¤",
            "text_input": "í…ìŠ¤íŠ¸ì…ë ¥",
            "date_input": "ë‚ ì§œì…ë ¥",
            "scale": "ì²™ë„",
        }
        for q_type, tstat in stats["type_statistics"].items():
            if tstat["total"] > 0:
                rate = tstat["matched"] / tstat["total"] * 100
                print(f"  â€¢ {type_name_map.get(q_type, q_type)}: "
                      f"{tstat['matched']}/{tstat['total']} ({rate:.1f}%)")

        # ë§¤ì¹­ ì‹¤íŒ¨ ìƒ˜í”Œ
        print(f"\n  ë§¤ì¹­ ì‹¤íŒ¨ ì£¼ìš” ë¬¸í•­ (ì¹´í…Œê³ ë¦¬ë³„):")
        failed_by_category = {}
        for m in matches:
            if not m["matched"] and m.get("reference"):
                cat = m.get("category", "ë¯¸ë¶„ë¥˜")
                failed_by_category.setdefault(cat, []).append(m)

        for cat, ms in failed_by_category.items():
            if ms:
                print(f"\n  [{cat}] - {len(ms)}ê°œ ì‹¤íŒ¨")
                for m in ms[:3]:
                    ref_text = m["reference"]["question_text"]
                    if len(ref_text) > 50:
                        ref_text = ref_text[:50] + "..."
                    print(f"    â€¢ P{m['page_number']}: {ref_text}")

    def _save_results(self, stats, matches, ref_questions, ocr_questions):
        ts = datetime.now().strftime("%Y%m%d_%H%M%S")
        # JSON
        json_path = self.results_dir / f"crf_evaluation_{ts}.json"
        with open(json_path, "w", encoding="utf-8") as f:
            import json
            json.dump(
                {
                    "timestamp": ts,
                    "statistics": stats,
                    "matches": serialize_matches(matches),
                    "reference_question_count": len(ref_questions),
                    "ocr_question_count": len(ocr_questions),
                },
                f,
                ensure_ascii=False,
                indent=2,
            )
        print(f"\n ìƒì„¸ ê²°ê³¼: {json_path}")

        # ë§¤ì¹­ ê²°ê³¼ CSV
        rows = []
        for m in matches:
            rows.append(
                {
                    "page": m["page_number"],
                    "category": m.get("category", ""),
                    "matched": m["matched"],
                    "similarity": m["similarity"],
                    "cer": m.get("cer"),
                    "wer": m.get("wer"),
                    "accuracy": m.get("accuracy"),
                    "gpt_confidence": m.get("gpt_confidence"),
                    "ref_question": m["reference"]["question_text"] if m.get("reference") else "",
                    "ocr_question": m["ocr"]["question_text"] if m.get("ocr") else "",
                    "question_type": m["reference"].get("question_type", "") if m.get("reference") else "",
                    "is_table_item": m["reference"].get("is_table_item", False) if m.get("reference") else False,
                    "ocr_only": m.get("ocr_only", False),
                }
            )
        if rows:
            df = pd.DataFrame(rows)
            csv_path = self.results_dir / f"crf_matching_{ts}.csv"
            df.to_csv(csv_path, index=False, encoding="utf-8-sig")
            print(f"ë§¤ì¹­ ê²°ê³¼ CSV: {csv_path}")

        # ì¹´í…Œê³ ë¦¬ ìš”ì•½ CSV
        cat_rows = []
        for cat, cstat in stats["category_statistics"].items():
            if cstat["total"] > 0:
                cat_rows.append(
                    {
                        "category": cat or "ë¯¸ë¶„ë¥˜",
                        "total": cstat["total"],
                        "matched": cstat["matched"],
                        "match_rate": cstat["matched"] / cstat["total"] * 100,
                        "avg_similarity": cstat.get("avg_similarity", 0.0),
                        "table_items": cstat["table_items"],
                        "table_matched": cstat["table_matched"],
                        "table_match_rate": (cstat["table_matched"] / cstat["table_items"] * 100)
                        if cstat["table_items"] > 0 else 0,
                    }
                )
        if cat_rows:
            df_cat = pd.DataFrame(cat_rows)
            cat_path = self.results_dir / f"crf_category_summary_{ts}.csv"
            df_cat.to_csv(cat_path, index=False, encoding="utf-8-sig")
            print(f"ì¹´í…Œê³ ë¦¬ ìš”ì•½: {cat_path}")

        # ì‹¤íŒ¨ ë¬¸í•­ ìƒì„¸
        failed_rows = []
        for m in matches:
            if not m["matched"] and m.get("reference"):
                failed_rows.append(
                    {
                        "page": m["page_number"],
                        "category": m.get("category", "ë¯¸ë¶„ë¥˜"),
                        "question_type": m["reference"].get("question_type", ""),
                        "is_table_item": m["reference"].get("is_table_item", False),
                        "reference_text": m["reference"]["question_text"],
                        "question_id": m["reference"].get("question_id", ""),
                    }
                )
        if failed_rows:
            df_failed = pd.DataFrame(failed_rows)
            failed_path = self.results_dir / f"crf_failed_items_{ts}.csv"
            df_failed.to_csv(failed_path, index=False, encoding="utf-8-sig")
            print(f"ì‹¤íŒ¨ ë¬¸í•­ ë¶„ì„: {failed_path}")
            
            
    def _inject_text_metrics(self, matches):
        for m in matches:
            if not m.get("matched"):
                continue
            ref = (m.get("reference") or {}).get("question_text") or ""
            hyp = (m.get("ocr") or {}).get("question_text") or ""
            if not ref and not hyp:
                m["cer"], m["wer"], m["accuracy"] = 0.0, 0.0, 1.0
                continue
            m["cer"] = cer(ref, hyp)
            m["wer"] = wer(ref, hyp)
            m["accuracy"] = accuracy(ref, hyp)
        
            try:
                conf = gpt_semantic_confidence(ref, hyp)
                if conf is not None:
                    m["gpt_confidence"] = conf
            except Exception:
                pass
    
    # ---------------------------
    # (5) ì°¸ì¡° PDF í˜ì´ì§€ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ë˜, ë¹„ì–´ìˆê±°ë‚˜ ë„ˆë¬´ ì§§ìœ¼ë©´ OCRë¡œ í´ë°±.
    # ---------------------------
                
    def _get_reference_pages_with_fallback(self, reference_pdf: str, min_len: int = 10, zoom: float = 2.5):
        """
        ì°¸ì¡° PDF í˜ì´ì§€ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ë˜, ë¹„ì–´ìˆê±°ë‚˜ ë„ˆë¬´ ì§§ìœ¼ë©´ OCRë¡œ í´ë°±.
        min_len: ì´ ê¸¸ì´ ë¯¸ë§Œì´ë©´ OCR ìˆ˜í–‰
        zoom: OCR í’ˆì§ˆì„ ìœ„í•œ ë Œë” ë°°ìœ¨
        """
        ref_texts = {p: t for p, t in iter_pdf_pages_text(reference_pdf, max_pages=MAX_PAGES_PER_RUN)}
        ocr_client = getattr(self, "ocr_client", None) or NaverOCRClient()

        # ì´ë¯¸ì§€ OCRë¡œ ë¹ˆ/ì§§ì€ í˜ì´ì§€ë§Œ ì±„ìš°ê¸° (ì „ì²´ í˜ì´ì§€)
        for p, img in iter_pdf_pages_as_images(reference_pdf, out_dir=self.results_dir, zoom=zoom, max_pages=MAX_PAGES_PER_RUN):
            if (not ref_texts.get(p)) or len((ref_texts[p] or "").strip()) < min_len:
                ocr_res = ocr_client.extract_text_from_image(str(img))
                ref_texts[p] = (ocr_res.get("text") or "").strip()
            try:
                img.unlink(missing_ok=True)
            except Exception:
                pass
        return [(p, ref_texts[p]) for p in sorted(ref_texts.keys())]


def main():
    print("ì˜ë£Œ CRF ë¬¸í•­ ê¸°ë°˜ OCR ì •í™•ë„ í‰ê°€ ì‹œìŠ¤í…œ")
    print("=" * 80)

    # í™˜ê²½ë³€ìˆ˜ í™•ì¸
    env_check = {
        "OpenAI API": bool(os.getenv("OPENAI_API_KEY")),
        "Naver OCR URL": bool(os.getenv("NAVER_OCR_API_URL")),
        "Naver Secret": bool(os.getenv("NAVER_OCR_SECRET_KEY")),
    }
    print("í™˜ê²½ ì„¤ì • ìƒíƒœ:")
    for k, ok in env_check.items():
        print(f"  {'âœ…' if ok else 'âŒ'} {k}")
    if not all(env_check.values()):
        print("\n  ì¼ë¶€ API ì„¤ì •ì´ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤.")
        print("   .env íŒŒì¼ì— ë‹¤ìŒ ë‚´ìš©ì„ ì„¤ì •í•˜ì„¸ìš”:")
        print("   - OPENAI_API_KEY")
        print("   - NAVER_OCR_API_URL")
        print("   - NAVER_OCR_SECRET_KEY")

    reference_pdf = "data/input/3_WSCHí‘œì¤€ê¶Œê³ ì¦ë¡€ê¸°ë¡ì„œ(CRF)ì–‘ì‹Ver_3_0.pdf"
    scanned_pdf = "data/input/Original Scan.pdf"

    # ê²½ë¡œ í™•ì¸
    if not Path(reference_pdf).exists():
        print(f"\nì°¸ì¡° PDF ì—†ìŒ: {reference_pdf}")
        return
    if not Path(scanned_pdf).exists():
        print(f"\nìŠ¤ìº” PDF ì—†ìŒ: {scanned_pdf}")
        return

    evaluator = MedicalCRFOCREvaluator()

    try:
        start = time.time()
        print(f"\n  í‰ê°€ ì‹œì‘")
        print(f"   ì°¸ì¡°: {reference_pdf}")
        print(f"   ìŠ¤ìº”: {scanned_pdf}")
        results = evaluator.evaluate(reference_pdf, scanned_pdf)
        elapsed = time.time() - start
        print(f"\n í‰ê°€ ì™„ë£Œ (ì†Œìš”ì‹œê°„: {elapsed:.1f}ì´ˆ)")
        print(f"   ì´ {results['statistics']['total_questions']}ê°œ ë¬¸í•­ í‰ê°€")
        print(f"   ë§¤ì¹­ë¥ : {results['statistics']['match_rate']:.1f}%")
    except KeyboardInterrupt:
        print("\n ì‚¬ìš©ì ì¤‘ë‹¨")
    except Exception as e:
        print(f"\n ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()
